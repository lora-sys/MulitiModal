import numpy as np
import pandas as pd
from scipy.signal import medfilt
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split


# --- 1. æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå‡½æ•° ---
def generate_labeled_data(mode, duration=100, fs=50):
    t = np.linspace(0, duration, duration * fs)
    if mode == 0:  # ç©ºè½½: åªæœ‰ä½åŠ›åº¦å’Œçº¯åº•å™ª
        signal = 20 + np.random.normal(0, 1.5, len(t))
    elif mode == 1:  # æŸ”å’Œ: é¢‘ç‡æ…¢(0.1Hz), æŒ¯å¹…å°(10)
        signal = (
            40 + 10 * np.sin(2 * np.pi * 0.1 * t) + np.random.normal(0, 1.5, len(t))
        )
    elif mode == 2:  # æ·±åº¦: é¢‘ç‡å¿«(0.5Hz), æŒ¯å¹…å¤§(30)
        signal = (
            60 + 30 * np.sin(2 * np.pi * 0.5 * t) + np.random.normal(0, 1.5, len(t))
        )

    # æ¨¡æ‹ŸæŠ•æ¯’ (æ³¨å…¥ 0.5% çš„å¼‚å¸¸ç‚¹)
    poison_idx = np.random.choice(
        len(signal), size=int(len(signal) * 0.005), replace=False
    )
    signal[poison_idx] += np.random.choice([-40, 40], size=len(poison_idx))

    return signal


# --- 2. æ ¸å¿ƒæ¸…æ´— Pipeline (å¤ç”¨ä¹‹å‰çš„ä¸“ä¸šä¿®å¤é€»è¾‘) ---
def professional_cleaning_pipeline(raw_signal, fs=50):
    df = pd.DataFrame({"raw": raw_signal})
    # 3-Sigma æ£€æµ‹
    rolling = df["raw"].rolling(window=15, center=True)
    mu, std = rolling.mean(), rolling.std()
    is_anomaly = (df["raw"] > mu + 3 * std) | (df["raw"] < mu - 3 * std)

    # ä¿®å¤ï¼šå¼‚å¸¸ç‚¹è®¾ä¸º NaN å¹¶æ’å€¼
    df["clean"] = df["raw"].copy()
    df.loc[is_anomaly, "clean"] = np.nan
    df["clean"] = (
        df["clean"].interpolate().fillna(method="bfill").fillna(method="ffill")
    )

    # å¹³æ»‘
    return df["clean"].rolling(window=15, center=True, min_periods=1).mean().values


# --- 3. ç‰¹å¾æå–å‡½æ•° ---
def get_features(signal, window_size=100):
    feats = []
    for i in range(0, len(signal) - window_size, window_size):
        seg = signal[i : i + window_size]
        feats.append(
            [
                np.mean(seg),  # å‡å€¼ -> åŠ›åº¦
                np.std(seg),  # æ ‡å‡†å·® -> æ³¢åŠ¨
                np.ptp(seg),  # å³°å³°å€¼ -> æŒ¯å¹…
                # ç®€å•è¿‡é›¶ç‡æ¨¡æ‹Ÿé¢‘ç‡ï¼šä¿¡å·ç©¿è¿‡å‡å€¼çš„æ¬¡æ•°
                np.sum(np.diff(seg > np.mean(seg)) != 0),
            ]
        )
    return np.array(feats)


# --- 4. å¼€å§‹ä¸»å®éªŒ ---

print("ğŸ› ï¸  æ­£åœ¨ç”Ÿæˆå¹¶æ¸…æ´—å¤šæ¨¡æ€æ•°æ®...")
# ç”Ÿæˆä¸‰ç±»æ•°æ®
s0 = generate_labeled_data(0)
s1 = generate_labeled_data(1)
s2 = generate_labeled_data(2)

# æ¸…æ´—æ•°æ®
c0 = professional_cleaning_pipeline(s0)
c1 = professional_cleaning_pipeline(s1)
c2 = professional_cleaning_pipeline(s2)

# æå–ç‰¹å¾
f0 = get_features(c0)
f1 = get_features(c1)
f2 = get_features(c2)

# åˆå¹¶æ•°æ®é›†
X = np.vstack([f0, f1, f2])
y = np.array([0] * len(f0) + [1] * len(f1) + [2] * len(f2))

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# è¯„ä¼°
y_pred = clf.predict(X_test)
print("\nğŸ¯ æŒ‰æ‘©æ¨¡å¼è¯†åˆ«ç»“æœ:")
print(f"å‡†ç¡®ç‡ (Accuracy): {accuracy_score(y_test, y_pred):.2%}")
print("\nåˆ†ç±»æŠ¥å‘Š:")
print(classification_report(y_test, y_pred, target_names=["ç©ºè½½", "æŸ”å’Œ", "æ·±åº¦"]))

# æ‰“å°ç‰¹å¾é‡è¦æ€§ (çœ‹æ¨¡å‹æœ€çœ‹é‡å“ªä¸ªæŒ‡æ ‡)
importances = clf.feature_importances_
feat_names = ["å¹³å‡åŠ›åº¦", "åŠ›åº¦æ³¢åŠ¨", "å‹åŠ›æŒ¯å¹…", "æ³¢åŠ¨é¢‘ç‡"]
for name, imp in zip(feat_names, importances):
    print(f"ç‰¹å¾ [{name}] å¯¹é¢„æµ‹çš„è´¡çŒ®åº¦: {imp:.2%}")
