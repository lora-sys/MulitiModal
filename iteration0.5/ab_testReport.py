import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

# 1. å‡†å¤‡æ•°æ®
# åŠ è½½åŸå§‹æ•°æ®ï¼ˆåŒ…å«çœŸå€¼å’ŒæŠ•æ¯’åçš„å™ªå£°ï¼‰
df = pd.read_csv("../iteration0.5/pressure_sim.csv")

# æ¨¡æ‹Ÿä¹‹å‰çš„æŠ•æ¯’é€»è¾‘ï¼ˆç¡®ä¿ A ç»„æœ‰æ¯’ï¼‰
np.random.seed(42)
poison_indices = np.random.choice(df.index[50:-50], size=10, replace=False)
for idx in poison_indices:
    # æ³¨å…¥ä¸€ä¸ªè¶³ä»¥è¯¯å¯¼å†³ç­–çš„å·¨å‹æ­£å‘è„‰å†² (è®© 20 å˜æˆ 70ï¼Œä»è€Œè§¦å‘é”™è¯¯æŠ¥è­¦)
    df.loc[idx, "noisy_signal"] += 50

# åŠ è½½ä½ ä¿®å¤åçš„æ•°æ® (B ç»„)
# æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ç›´æ¥ä»ä¹‹å‰çš„ä¿®å¤é€»è¾‘ä¸­æå–ç»“æœï¼Œæˆ–è€…é‡æ–°è¿è¡Œä¿®å¤
window_size = 15
df["filter_ma"] = df["noisy_signal"].rolling(window=window_size, center=True).mean()
df["rolling_std"] = df["noisy_signal"].rolling(window=window_size, center=True).std()
is_anomaly = (df["noisy_signal"] > (df["filter_ma"] + 3 * df["rolling_std"])) | (
    df["noisy_signal"] < (df["filter_ma"] - 3 * df["rolling_std"])
)

df["repaired"] = df["noisy_signal"].copy()
df.loc[is_anomaly, "repaired"] = np.nan
df["repaired"] = df["repaired"].interpolate().ffill().bfill()
df["final_recovered"] = df["repaired"].rolling(window=window_size, center=True).mean()

# 2. å®šä¹‰ AB Test ä»»åŠ¡ï¼šå‹åŠ›æ˜¯å¦ > 50ï¼Ÿ
threshold = 50

# åœ°é¢çœŸå€¼ (æˆ‘ä»¬å¸Œæœ›æ¨¡å‹è¾¾åˆ°çš„ç»ˆæç›®æ ‡)
y_true = (df["clean_signal"] > threshold).astype(int)

# A ç»„é¢„æµ‹ (ç›´æ¥ç”¨è„æ•°æ®)
y_pred_A = (df["noisy_signal"] > threshold).astype(int)

# B ç»„é¢„æµ‹ (ç”¨ä¿®å¤åçš„æ•°æ®)
y_pred_B = (df["final_recovered"] > threshold).astype(int)


# 3. è·‘åˆ†è¯„ä»·
def get_report(y_true, y_pred):
    return {
        "Accuracy": accuracy_score(y_true, y_pred),
        "Precision (æŠ¥è­¦å‡†ç¡®ç‡)": precision_score(y_true, y_pred),
        "Recall (æ¼æŠ¥ç‡)": recall_score(y_true, y_pred),
        "F1-Score": f1_score(y_true, y_pred),
    }


report_A = get_report(y_true, y_pred_A)
report_B = get_report(y_true, y_pred_B)

# 4. æ‰“å°æœ€ç»ˆæˆ˜æŠ¥
print("=" * 50)
print("       ğŸš€ ç»ˆæ AB Test è·‘åˆ†æŠ¥å‘Š ğŸš€")
print("=" * 50)
print(f"{'æŒ‡æ ‡':<20} | {'A ç»„ (å¸¦æ¯’æ•°æ®)':<15} | {'B ç»„ (ä¸“ä¸šä¿®å¤)':<15}")
print("-" * 55)

for metric in report_A.keys():
    valA = report_A[metric]
    valB = report_B[metric]
    mark = "â­" if valB > valA else ""
    print(f"{metric:<18} | {valA:15.4f} | {valB:15.4f} {mark}")

print("-" * 55)
# è®¡ç®—è¯¯æŠ¥ï¼ˆFalse Positivesï¼‰
fp_A = ((y_pred_A == 1) & (y_true == 0)).sum()
fp_B = ((y_pred_B == 1) & (y_true == 0)).sum()
print(f"è¯¯æŠ¥æ¬¡æ•° (False Alarms):  A ç»„ = {fp_A} æ¬¡ | B ç»„ = {fp_B} æ¬¡")
print(f"âœ… B ç»„å°†è¯¯æŠ¥é™ä½äº†: {((fp_A - fp_B) / fp_A) * 100:.1f}%")
print("=" * 50)
